{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "    \n",
    "Sample patches from DIV2K \n",
    "Calculate the bicubic psnr of each patch \n",
    "\n",
    "Calculate entropy of gradients of each grayscaled patch \n",
    "\n",
    "Plot entropy vs. psnr \n",
    "Fit the line\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import core\n",
    "import torch\n",
    "import matplotlib.pyplot as plt \n",
    "import torchvision.transforms as transforms\n",
    "import skimage.measure    \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE these are the corrupted LR and HR pairs of 900 images. \n",
    "## They are corrupted using \n",
    "## https://github.com/sanghyun-son/bicubic_pytorch/blob/master/core.py to do matlab like bicubic interpolation.\n",
    "\n",
    "base_dir = \"path/to/DIV2K/after/using/PRE Processing/Script\"\n",
    "hr_image_paths = sorted(glob.glob(os.path.join(base_dir,\"DIV2K_train_HR/\") + \"*\"))\n",
    "lr_image_paths = sorted(glob.glob(os.path.join(base_dir,\"DIV2K_train_LR_bicubic/X4/\") + \"*\"))\n",
    "\n",
    "\n",
    "## DIV2K Training Data is the first 800 images. Only include those.\n",
    "hr_image_paths = hr_image_paths[:800]\n",
    "lr_image_paths = lr_image_paths[:800]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Step 1: Sample LR, HR patches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def sample_patches(lr_img_path, hr_img_path, patch_size, scale,num_patches):\n",
    "    # Load images\n",
    "    random.seed(123)\n",
    "    lr_img = Image.open(lr_img_path)\n",
    "    hr_img = Image.open(hr_img_path)\n",
    "    \n",
    "    # Convert images to numpy arrays\n",
    "    lr_arr = np.array(lr_img)\n",
    "    hr_arr = np.array(hr_img)\n",
    "    \n",
    "    # Initialize arrays to store patches\n",
    "    lr_patches = np.zeros((num_patches, patch_size, patch_size, lr_arr.shape[2]))\n",
    "    hr_patches = np.zeros((num_patches, patch_size*scale, patch_size*scale, hr_arr.shape[2]))\n",
    "    \n",
    "    # Sample patches randomly\n",
    "    for i in range(num_patches):\n",
    "        # Choose random location for patch\n",
    "        x = random.randint(0, lr_arr.shape[0] - patch_size)\n",
    "        y = random.randint(0, lr_arr.shape[1] - patch_size)\n",
    "        \n",
    "        # Extract patch from LR and HR images\n",
    "        # Add patch to patch arrays\n",
    "        lr_patches[i] = lr_arr[x:x+patch_size, y:y+patch_size, :]\n",
    "        hr_patches[i] =  hr_arr[x*scale:x*scale+patch_size*scale, y*scale:y*scale+patch_size*scale, :]\n",
    "    \n",
    "    \n",
    "    ## convert them to uint8 \n",
    "    lr_patches = lr_patches.astype(\"uint8\") \n",
    "    hr_patches = hr_patches.astype(\"uint8\") \n",
    "    return lr_patches, hr_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psnr(a,b,rgb_range=255):\n",
    "    diff = (a - b) / rgb_range\n",
    "    mse = diff.pow(2).mean()\n",
    "    if mse == 0:\n",
    "        print(\"MSE here was 0. Math domain error!\")\n",
    "        return -1\n",
    "    \n",
    "    return -10 * math.log10(mse)\n",
    "\n",
    "def calculate_bicubic_psnrs(lr_patches,hr_patches, patch_size,scale):\n",
    "    '''given two numpy arrays of lr patches and hr patches\n",
    "    use the core implementation to calculate the bicbuc psnr. \n",
    "    this requires converting to tensor first\n",
    "    \n",
    "    This is done in 0-255 range.\n",
    "    '''\n",
    "    \n",
    "\n",
    "    vals = []\n",
    "    \n",
    "    for i in range(len(lr_patches)):\n",
    "        \n",
    "        \n",
    "        upsampled = core.imresize(lr_patches[i], sizes=(patch_size*scale, patch_size*scale))        \n",
    "        upsampled = upsampled.clip(0,255).int() \n",
    "        psnr = calculate_psnr(hr_patches[i],upsampled)\n",
    "        vals.append(psnr)\n",
    "        \n",
    "    return vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "class Gradient_Net(nn.Module):\n",
    "\n",
    "    def __init__(self,device,pad=0):\n",
    "\n",
    "        super(Gradient_Net, self).__init__()\n",
    "        kernel_x = [[-1., 0., 1.], [-2., 0., 2.], [-1., 0., 1.]]\n",
    "        kernel_x = torch.FloatTensor(kernel_x).unsqueeze(0).unsqueeze(0).to(device)\n",
    "        kernel_y = [[-1., 0., 1.], [-2., 0., 2.], [-1., 0., 1.]]\n",
    "        kernel_y = torch.FloatTensor(kernel_y).unsqueeze(0).unsqueeze(0).to(device)\n",
    "        self.weight_x = nn.Parameter(data=kernel_x, requires_grad=False)\n",
    "        self.weight_y = nn.Parameter(data=kernel_y, requires_grad=False)\n",
    "        self.pad = pad\n",
    "\n",
    "    def forward(self, x):\n",
    "        grad_x = F.conv2d(x, self.weight_x,padding=self.pad)\n",
    "        grad_y = F.conv2d(x, self.weight_y,padding=self.pad)\n",
    "        gradient = torch.abs(grad_x) + torch.abs(grad_y)\n",
    "        return gradient\n",
    "\n",
    "\n",
    "def calculate_entropy_gradients(patches):\n",
    "    '''\n",
    "    calculates the entropy of the gradients of the grayscaled patches\n",
    "    \n",
    "    this calculation should be in 0-1 range\n",
    "    '''\n",
    "    \n",
    "    patches = patches / 255.0\n",
    "    \n",
    "    ## Converts a torch.*Tensor of shape C x H x W or a numpy ndarray of shape H x W x C to a PIL \n",
    "    ## Image while preserving the value range.\n",
    "    pre_process = transforms.Compose([transforms.ToPILImage(),\n",
    "                                  transforms.Grayscale(num_output_channels=1),\n",
    "                                  transforms.ToTensor()])\n",
    "\n",
    "    #step A: convert to grayscale first.\n",
    "    gray_patches = torch.stack([pre_process(i) for i in patches])\n",
    "    \n",
    "    #step B: get gradients.\n",
    "    gradients = gradient_net(gray_patches.to(device)).cpu().numpy()\n",
    "    \n",
    "    #step C: get entropy.\n",
    "    entropies = [ent(e) for e in gradients]\n",
    "\n",
    "    return entropies\n",
    "    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "patch_size = 48\n",
    "num_patches = 100  \n",
    "scale = 4\n",
    "counter = 0\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gradient_net = Gradient_Net(device,1).to(device)\n",
    "ent = skimage.measure.shannon_entropy\n",
    "\n",
    "global_xs =[]\n",
    "global_ys =[]\n",
    "\n",
    "for lr_img_path, hr_img_path in zip(lr_image_paths,hr_image_paths):\n",
    "    \n",
    "    print(counter)\n",
    "    counter+=1\n",
    "    \n",
    "\n",
    "\n",
    "    lr_patches, hr_patches = sample_patches(lr_img_path, hr_img_path, \n",
    "                                            patch_size,scale, num_patches)\n",
    "\n",
    "    # bring channels first for pytorch tensor.\n",
    "\n",
    "    lr_patches_tensor = torch.Tensor(lr_patches).permute(0,3,1,2) \n",
    "    hr_patches_tensor = torch.Tensor(hr_patches).permute(0,3,1,2) \n",
    "\n",
    "    ## calculate bicubic psnrs \n",
    "    bcs = calculate_bicubic_psnrs(lr_patches_tensor,hr_patches_tensor, patch_size,scale)\n",
    "\n",
    "    ## calculate entropy of gradients \n",
    "    ents = calculate_entropy_gradients(hr_patches_tensor)\n",
    "\n",
    "\n",
    "    ## save them \n",
    "    global_xs += ents \n",
    "    global_ys += bcs \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.array(global_xs) \n",
    "ys = np.array(global_ys) \n",
    "\n",
    "\n",
    "# remove patches that had a psnr of -1 as the MSE there was 0. \n",
    "## or replace them actually with PSNR of max PSNR. or 1000 \n",
    "## also remove super high PSNR patches / outliers  \n",
    "\n",
    "filter_ = (np.array(ys) >= 0) & (np.array(ys) <= 60)\n",
    "xs = xs[filter_]\n",
    "ys = ys[filter_] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,1,figsize=(10,10),sharey=True,sharex=True)\n",
    "\n",
    "\n",
    "plt.scatter(xs,ys,color='black')\n",
    "plt.yticks(fontsize=13 ) \n",
    "plt.xticks(fontsize=13 )     \n",
    "z = np.poly1d(np.polyfit(xs,ys,1))\n",
    "plt.plot(xs, z(xs),color='red')   \n",
    "fig.text(0.515, 0.05, 'Entropy', ha='center',fontsize=20)\n",
    "fig.text(0.05, 0.5, 'PSNR', va='center', rotation='vertical',fontsize=20)\n",
    "plt.savefig(\"./****_entropy_vs_psnr_DIV2K.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
